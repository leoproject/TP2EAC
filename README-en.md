# TP2EAC
[Version Portuguese](README.md)

<img align="left" src="https://media.giphy.com/media/ADgfsbHcS62Jy/giphy.gif" width="200" height="200" /> 

TP2EAC - It is a project carried out by a discipline of the 4th year of the Master in Computer Engineering, from the profile of Intelligent Systems. Just aim and get a classification model to produce good results. In this work we have the following problems: Preparation and analysis of a data set related to the characteristics of employees of multiple companies, in order to predict the individual's annual salary level. This project is based on a set of case studies, which present information regarding employees of companies around the world, since they have multiple characteristics about the individual.


   


## About Team
The developer team is four master students from University of Minho, Braga, Portugal.

* [Daniel Assunção](https://github.com/guiyrt)
* [Diogo Ferreira ](https://github.com/DiogoFerreira99)
* [Leonardo Silva](https://github.com/leoproject)
* [Pedro Pinheiro](https://github.com/Pinheiro9655)
  
## Dataset
The dataset provided to work on the proposed problem is found in the [resources] (resources /) directory which contain:

1. training.csv, which presents the case studies to be applied exclusively for the training of the predictive model;

2. test.csv, which presents the case studies to be applied exclusively for the analysis and validation of the predictive model;

3. attribute_info.docx, where details about the attributes of the given data set are presented. Containing 14 attributes and 1 annual salary classification target information if the employee receives 50 thousand per year.



# Development Methodology:

<img align="right" src="https://media.giphy.com/media/l4pTsNgkamxfk2ZLq/giphy.gif" width="200" height="150"/> 

The methodology adopted by the team is the CRISP-DM (Cross Industry Standard Process for Data Mining) consists of a cycle consisting of 6 phases.

1. **Business Study:** This initial phase was the study of the dataset to understand which objective and attributes are present in the dataset;

2. **Data Analysis:** This phase was accomplished by studying the data and features, present in the training dataset in particular. This phase can be found in the [data analysis notebook](data_analysis/TP2EAC_AnaliseDados.ipynb);

3. **Data Preparation:** In this phase, a [notebook](Data_Preparation/TP2EAC_Preparação_dos_Dados.ipynb) was made which had [input](Data_Preparation/Input) the training and test datasets, provided by the teaching team.
   
   Next, missing values, correlations, feature engineering and other techniques were verified. The [output](Data_Preparation/Output) of this notebook was the generation of new datasets. They are training and testing, with data processing and others in addition to data processing contain normalization. Resulting in 4 datasets (2 of training and 2 of test). These will be used at a later stage;

4. **Modeling of Algorithms:** For this phase to standardize the development flow of the models, we made a [standard notebook](models/reglog/TP2EAC-STANDARD-MODEL.ipynb) using the logistic regression algorithm. Which output is the classification model of the algorithm in use. Once all the models generated by the chosen algorithms are saved, we will move on to the next phase;

5. **Evaluation of Models:** This phase has the [evaluation notebook](benchmark/TP2AEC-AVALIACAO.ipynb) with all models so that we can view and compare the results of the models using the test datasets normalized or not. Once it has been decided which is the best classification model for this problem, it will move on to the next phase;
   
6. **Development:** This phase is to put the model chosen in the previous phase into production, for this Heroku was used and an API was created to access the model with Flask, which is in a [repository](https://github.com/leoproject/appModel) separately. If you want to test the api with the model in production we have a notebook for that in the directory [testApi](testApi/Testar%20Modelo.ipynb) and we also have an [APK](testApi/appEquipa9.apk), to install on Android operating systems, for those who want to try out the created application. As well as the IONIC project of the application [App Project](testApi/AppAEC/).




## Conclusion
With the resolution of this work, the group developed capabilities to create and train classification models using a wide variety of different algorithms. We have also evolved in terms of data analysis and preparation, which are two important phases for any development of a classification and forecasting method.

That said, we conclude that the best model trained by our group, if we analyze only by the accuracy of the models, is the one that implements the K-Nearest-Neighbors algorithm. However, what the group would choose for the Development phase, according to previously established criteria, we would choose the model that implements the Logistic Regression algorithm, using the method created by our group.