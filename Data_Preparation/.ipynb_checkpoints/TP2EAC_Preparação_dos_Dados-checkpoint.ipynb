{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Bibliotecas para Análise dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ler-se os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from google.colab import files\n",
    "##file1 = files.upload()\n",
    "##file2 = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Input/training.csv',sep=';')\n",
    "df_test = pd.read_csv('./Input/test.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informações sobre o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breve descrição do dataset, porém traz conhecimento de features que são do tipo númerico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Informações sobre as features do tipo objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificar nome das colunas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observação problema com Space\n",
    "Foi observado que os nomes das colunas (features) estavam com espaçamento. E para garantir foi verificado e retirado os espaçamentos dos valores destas features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteSpaces(df):\n",
    "    #deletar espaço no nome das colunas e mudança do nome da coluna alvo\n",
    "    df.columns = ['age','workclass','fnlwgt','education','education_num','marital_status','occupation','relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','target']\n",
    "    lista = ['workclass','education','marital_status','occupation','relationship','race','sex','native_country','target']\n",
    "    for i in lista:\n",
    "        df[i] = df[i].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteSpaces(df_train)\n",
    "deleteSpaces(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os missing values\n",
    "Usando a função **.info()** acima retornou que não há missing values. No entanto, a descrição dada pelo dataset diz-nos que os missing values foram substituídos por **?**.\n",
    "\n",
    "Desta forma, verificamos quantos missing values tem o dataset de treino e de teste: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isin(['?']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isin(['?']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decisão dos Missing Values\n",
    "Depois de observar os missing values presentes tanto no dataset de treino como no dataset de teste, chegou-se a conclusão que a melhor decissão é deletar os registos os quais contenham missing values. Pois o país de origem, classe de trabalho e ocupação não temos como substituir por média ou generalização destes campos, presentes no datasets. Então foi feito os seguintes passos:\n",
    "\n",
    "1. Foi substituído os valores de **?** por **NaN**;\n",
    "2. Consequentemente foi deletado os registos (linhas) do dataset que continham valores **NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteMissingValues(df):\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['native_country'] = df['native_country'].replace('?',np.nan)\n",
    "    df.dropna(how ='any',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteMissingValues(df_train)\n",
    "deleteMissingValues(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de feature engineering, foi dada pela observação das features a qual fazemos um agrupamento de valores dos quais achamos pertinentes. De acordo com o estudo da analise dos dados, isto posto, fizemos os seguintes agrupamentos:\n",
    "\n",
    " **1. Por faixa etária de idade:**\n",
    " \n",
    "  Como temos 42 paises e a legislação de cada um possui diferentes faixa etarias do que seria um jovem, adolescentes e idosos. Foi criada faixa etarias por decisão da equipa:\n",
    "\n",
    "Dos 0 aos 25 young\n",
    "\n",
    "Dos 26 aos 45 adult\n",
    "\n",
    "Dos 46 aos 65 seniors\n",
    "\n",
    "Maiores de 65 old\n",
    "  \n",
    " **2. Por horas trabalho na semana:**\n",
    " \n",
    "   O mesmo vale para criação do agrupamento desta feature, foi dividido da seguinte forma:\n",
    "   \n",
    "par-time (0-25)\n",
    "\n",
    "full-time (25-40)\n",
    "\n",
    "over-time (40-60)\n",
    "\n",
    "Workaholic (60+).\n",
    "   \n",
    " **3. Por status civil.**\n",
    " \n",
    "   A criação dessa nova feature foi observando que na pratica tinhamos casados e solteiros  \n",
    "   \n",
    "   **Solteiro:** Divorced, Never-married, Separated, Widowed.\n",
    "   \n",
    "   **Casado:** Married-AF-spouse, Married-civ-spouse, Married-spouse-absent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_range(element):\n",
    "    if element <= 25:\n",
    "        return 'young'\n",
    "    elif (element>25 and element <=45):\n",
    "        return 'adult'\n",
    "    elif (element>45 and element <=65):\n",
    "        return 'seniors'\n",
    "    else:\n",
    "        return 'Old'\n",
    "    \n",
    "def work(element):\n",
    "    if element <= 25:\n",
    "        return 'part-time'\n",
    "    elif (element>25 and element <=40):\n",
    "        return 'full-time'\n",
    "    elif (element>40 and element <=60):\n",
    "        return 'over-time'\n",
    "    else:\n",
    "        return 'Workaholic'\n",
    "    \n",
    "def createFeature(df):\n",
    "    target = df.target\n",
    "    df = df.drop(columns=['target'])\n",
    "    df['age_range'] = df['age'].apply(age_range)\n",
    "    df['work'] = df['hours_per_week'].apply(work)\n",
    "    df['status_civic'] = df['marital_status'].map({'Married-civ-spouse':'married',\n",
    "                                                         'Never-married':'single',\n",
    "                                                         'Divorced':'single',\n",
    "                                                         'Separated':'single',\n",
    "                                                         'Widowed':'single',\n",
    "                                                         'Married-spouse-absent':'married',\n",
    "                                                         'Married-AF-spouse':'married'})\n",
    "     \n",
    "    df['target'] = target\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = createFeature(df_train)\n",
    "df_test = createFeature(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar informações sobre as features:\n",
    "\n",
    "Foi necessário ter uma informação sobre cada feature de forma mais ampla. Descrito a seguir:\n",
    "\n",
    "**1. feature**\n",
    "\n",
    "Nome da feature em questão analisada.\n",
    "\n",
    "**2. dtype**\n",
    "\n",
    "Tipo dos registos desta feature.\n",
    "\n",
    "**3. num_null**\n",
    "\n",
    "Número de registos nulos desta feature.\n",
    "\n",
    "**4. num_unique**\n",
    "\n",
    "Quantos valores unicos possui esta feature.\n",
    "\n",
    "**5. record per unique**\n",
    "\n",
    "Numero de registos total por valores unicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_check(df):\n",
    "    \n",
    "    columns = df.columns\n",
    "    list = []\n",
    "    for feature in columns:\n",
    "        dtype    = df[feature].dtypes\n",
    "        num_null = df[feature].isnull().sum()\n",
    "        num_unique = df[feature].nunique()\n",
    "        num_reg_type = int(len(df)/df[feature].nunique())\n",
    "        list.append([feature, dtype, num_null,num_unique, num_reg_type])\n",
    "    \n",
    "    df_checked = pd.DataFrame(list)\n",
    "    df_checked.columns = ['feature','dtype','num_null','num_unique','record per unique']\n",
    "    df_checked = df_checked.sort_values(by='dtype', axis=0, ascending=True)\n",
    "    \n",
    "    return df_checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_check(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Com base na tabela podemos chegar as seguintes analises e conclusões:\n",
    "\n",
    "1. Temos **12 features** do tipo **objeto** e **6 features** do tipo **int64**;\n",
    "\n",
    "\n",
    "2. A **feature education_num** e **education** ambas dizem respeito ao mesmo dado só que em tipos diferentes. \n",
    "Aqui precisaremos deletar uma delas. Acredito como iremos colocar o algoritmo em produção, devemos deletar a education_num;\n",
    "\n",
    "\n",
    "3. A **feature fnlwgt** basicamente tem um único registo por valor único, logo ela não possui insinificância para o dataset, só irá introduzir ruído. Pois ela seria basicamente como um id para os registos. Logo é mais uma feature candidata a ser excluída;\n",
    "\n",
    "\n",
    "4. Próximo passo seria fazer **label enconder** das **12 features** do tipo objeto para transformá-los no tipo int64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformType(df):\n",
    "    labelenconder = LabelEncoder()\n",
    "    # mudar tipo do valor da feature sexo\n",
    "    df['sex'] = labelenconder.fit_transform(df['sex'])\n",
    "    # mudar tipo do valor da feature raça\n",
    "    df['race'] = labelenconder.fit_transform(df['race'])\n",
    "    # mudar tipo do valor da feature conjugal\n",
    "    df['marital_status'] = labelenconder.fit_transform(df['marital_status'])\n",
    "    # mudar tipo do valor da feature relação\n",
    "    df['relationship'] =  labelenconder.fit_transform(df['relationship'])\n",
    "    # mudar tipo do valor da feature classe trabalhadora\n",
    "    df['workclass'] = labelenconder.fit_transform(df['workclass'])\n",
    "    # mudar tipo do valor da feature educação\n",
    "    #df['education'] = labelenconder.fit_transform(df['education'])\n",
    "    # mudar tipo do valor da feature  ocupação\n",
    "    df['occupation'] = labelenconder.fit_transform(df['occupation'])\n",
    "    # mudar tipo do valor da feature target\n",
    "    df['target'] = labelenconder.fit_transform(df['target'])\n",
    "    # mudar tipo do valor da feature nação de origem\n",
    "    df['native_country'] = labelenconder.fit_transform(df['native_country'])\n",
    "    # mudar tipo do valor da  feature criada status civiel ( solteiro ou casado)\n",
    "    df['status_civic'] = labelenconder.fit_transform(df['status_civic'])\n",
    "    # mudar tipo do valor da  feature criada sobre carga de trabalho work \n",
    "    df['work'] = labelenconder.fit_transform(df['work'])\n",
    "    # mudar tipo do valor da  feature criada faixa etaria\n",
    "    df['age_range'] = labelenconder.fit_transform(df['age_range'])\n",
    "    \n",
    "    #education\n",
    "    df['education'] = df['education'].map({'Preschool':1,\n",
    "                                           '1st-4th':2,\n",
    "                                           '5th-6th': 3,\n",
    "                                           'Doctorate':16,\n",
    "                                           '12th':8,  \n",
    "                                           '9th':5,\n",
    "                                           'Prof-school':15,\n",
    "                                           '7th-8th':4,\n",
    "                                           '10th':6,\n",
    "                                           'Assoc-acdm':12,\n",
    "                                           '11th':7,\n",
    "                                           'Assoc-voc':11,\n",
    "                                           'Masters':14,\n",
    "                                           'Bachelors':13,\n",
    "                                           'Some-college':10,\n",
    "                                           'HS-grad':9}).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformType(df_train)\n",
    "transformType(df_test)\n",
    "type_check(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlação das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "# define the mask to set the values in the upper triangle to True\n",
    "mask = np.triu(np.ones_like(df_train.corr(), dtype=np.bool))\n",
    "heatmap = sns.heatmap(df_train.corr(), mask=mask, vmin=1, vmax=-1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Correlação dos Atributos', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificando as features existente nos dados e as concluões que chegamos são:**\n",
    "\n",
    "1. O que nos impressionou foi o workclass e occupation não terem uma correlação sginificativa com a target, esperavamos que o tipo de organização e tipo de função do individuo influencia-se seu ganho por ano;\n",
    "\n",
    "\n",
    "2. A feature **fnlwgt** como mencionad para além de ter um valor unico para um registo, tem uma correlção baixa com a target;\n",
    "\n",
    "\n",
    "3. Das features criadas somente a feature status_civic tem uma correlação superior a feature que a originou marital_status. Desta forma, é a única que deve ser preservada das 3 features criadas e a marital_status deletamos;\n",
    "\n",
    "\n",
    "4. Iremos usar as features que tem uma correlação igual ou superir a 15% com a target. Desta forma, das 18 features só iremos utilizar 8 dessas e a target para criar modelos as seguintes features:\n",
    "\n",
    "   - age\n",
    "   - education\n",
    "   - relationship\n",
    "   - sex\n",
    "   - capital_gain\n",
    "   - capital_loss\n",
    "   - hours_per_week\n",
    "   - status_civic\n",
    "   - **target**\n",
    "   \n",
    "   \n",
    "   **No entanto**, fizemos teste estatístico para ver se essa corelação era significativa no notebook sobre análise dos dados a partir do **p-value**. Consequentemente das 8 features duas (sex e relationship) delas não rejeitasse a hipotese nula, logo elas não tem uma probabilidade de significância com a target. Acabamos por ficar com :\n",
    "   \n",
    "   - age\n",
    "   - education\n",
    "   - capital_gain\n",
    "   - capital_loss\n",
    "   - hours_per_week\n",
    "   - status_civic\n",
    "   - **target**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteFeatures(df, lista):\n",
    "    for i in lista:\n",
    "        df = df.drop(columns=[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = ['fnlwgt','native_country','workclass','occupation','sex','education_num','relationship','race','marital_status','work','age_range']\n",
    "#lista = ['fnlwgt','native_country','workclass','occupation','education_num','race','marital_status','work','age_range']\n",
    "\n",
    "df_train = deleteFeatures(df_train,lista)\n",
    "df_test  = deleteFeatures(df_test,lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados distribuição\n",
    "\n",
    "Nota-se um uma despradonização entre dos valores das features, em especial as variaveis capital_gain e capital_loss. Se olharmos essas duas features veremos que o desvio padrão delas em relação as demais contem um diferença muito grande. É aconselhavel aqui uma normalização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    target = df.target\n",
    "    df = df.drop(columns=['target'])\n",
    "    scaler = MinMaxScaler()\n",
    "    for i in df.columns:\n",
    "        df[[i]] = scaler.fit_transform(df[[i]])\n",
    "    df['target'] = target\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalize = normalize(df_train)\n",
    "df_normalize_test = normalize(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado \n",
    "Como resultado deste notebook iremos salvar os dataset de treino e teste já com o tratamento dos dados e outros dois datasets para além do tratamento eles estão com os dados normalizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Tratado \n",
    "Os dataset com o tratamento feitos nesse notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv',index=False)\n",
    "df_test.to_csv('df_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Normalizado \n",
    "Os dataset com o tratamento e normalização dos dados feitos nesse notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalize.to_csv('train_normalize.csv',index=False)\n",
    "df_normalize_test.to_csv('test_normalize.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
